{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/bads/blob/master/exercises/2_ex_descriptive_analytics.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BADS Exercise 2 on the foundations of descriptive analytics\n",
    "The second exercise comprises one more task to advance your skills in Python programming. It's main focus is on cluster analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Further exercises on Python programming\n",
    "The following exercise tasks revisit some concepts covered in [Tutorial 1 on Python programming](https://github.com/Humboldt-WI/bads/blob/master/tutorials/1_nb_python_intro.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using inbuilt functions and libraries\n",
    "In Python and other programming language, we use inbuilt functions all the time. Libraries like `NumPy` and `Pandas`, which offer a ton of functionality for handling and analyzing data, are the main reason why the Python language is such a good fit for data science. Let's practice our ability to access libraries and use their functions with some concrete tasks.\n",
    "\n",
    "The density of the normal distribution with mean $\\mu$ and variance $\\sigma$ is given as\n",
    "$$f(x | \\mu ,\\sigma ^{2}) = {\\frac {1}{\\sqrt {2\\sigma ^{2}\\pi}}}e^{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}}}$$\n",
    "\n",
    "Let's create a nice plot of the bell curve that is so famous and characteristic for the normal distribution. Below, we already made sure that relevant libraries are imported. First, define two variables that store the two parameters of the normal distribution; no need to spill out these parameters, right? Next generate some values $x$. Say you want to plot the bell curve for $x \\in \\{-3, 3\\} $. Use the `NumPy` function `linspace()` for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "miu = 0\n",
    "sigma = 1\n",
    "n = 100\n",
    "\n",
    "#help(np.linspace)\n",
    "x = np.linspace(-3,3,num=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for each value of $x$, compute the probability that a normally distributed random variable would be arbitrarily close to that value. To calculate the probability density of the normal distribution, you can use the function `norm.pdf`. The function is part of the *stats models library*, which we import below. So you can write something like `stats.norm.pdf(...)` where ... stands for the arguments that the function requires. Make sure to store the results of the computation in a variable **nvValues**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(stats.norm.pdf)\n",
    "nvValues = stats.norm.pdf(x,loc = miu, scale = sigma^2)\n",
    "\n",
    "#nvValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to plot. Create a simple graph of **nvValues** against **x** using the `plot()`function. Let's say you want your line to be in red color. Use the help and web search to find out how to plot a red line. Also make sure to label your axes; remember: never create a plot without axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#help(plt.plot)\n",
    "\n",
    "plt.plot(x,nvValues,color='red')\n",
    "plt.title('Density of the normal distribution')\n",
    "plt.xlabel('x∈{−3,3}')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exercises on descriptive analytics\n",
    "The following exercise tasks revisit some concepts covered in [Tutorial 2 on descriptive analytics](https://github.com/Humboldt-WI/bads/blob/master/tutorials/2_nb_descriptive_analytics.ipynb). \n",
    "\n",
    "### 2.1 Data generation\n",
    "We want to revisit kMeans and need some data for this purpose. Make use of the function `make_blobs()`, which is part of the `sklearn` library to generate some artificial data. Say we want to **create data with 4 clusters**. Make sure to configure the `make_blobs()` function appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for clustering\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "np.random.seed(88)\n",
    "\n",
    "n = 500 # no. samples\n",
    "centers = [(-5, 3), (-5, -3), (5, 3), (5, -3)]  # centers of the two Gaussian\n",
    "std = 1  # standard deviaton\n",
    "\n",
    "# Call the function and obtain your data\n",
    "X,y,c = make_blobs(n_samples=n, centers=centers, cluster_std=std,return_centers=True)\n",
    "\n",
    "#X.shape, y.shape, c.shape # ensure shape is as expected\n",
    "#y[:50]\n",
    "#c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 kMeans\n",
    "The second tutorial provided a *from scratch implementation* of the kMeans algorithm. Go back to the tutorial and copy/paste the relevant parts of the code into this notebook. This will allow you to run the algorithm here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From-scratch implementation of kMeans \n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b)**2)) # other distance measures also possible\n",
    "\n",
    "def label_cluster(n_samples, clusters):\n",
    "    \"\"\"each sample will get the label of the cluster it was assigned to\"\"\"\n",
    "    labels = np.empty(n_samples) # creates empty array as long as samples for future labels\n",
    "\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "        for sample_index in cluster:\n",
    "            labels[sample_index] = cluster_idx # assign labels to each sample\n",
    "    return labels\n",
    "\n",
    "def create_clusters(K, X, centroids):\n",
    "    \"\"\"Assign the samples to the closest centroids to create clusters\"\"\"\n",
    "    clusters = [[] for _ in range(K)] # creates a list of K number of lists\n",
    "    for idx, sample in enumerate(X):\n",
    "        centroid_idx = find_closest_centroid(sample, centroids) # find closest centroid for each sample\n",
    "        clusters[centroid_idx].append(idx) # create index list of closest centroids\n",
    "    return clusters\n",
    "\n",
    "def find_closest_centroid(sample, centroids):\n",
    "    \"\"\"Distance from each sample to every centroid\"\"\"\n",
    "    distances = [euclidean_distance(sample, point) for point in centroids] # calculate distance from each sample to each centroid\n",
    "    closest_index = np.argmin(distances) # take closest centroid (one with minimal distance)\n",
    "    return closest_index\n",
    "\n",
    "def update_centroids(X, K, n_features, clusters):\n",
    "    \"\"\"Assign mean value of cluster features to each centroid\"\"\"\n",
    "    centroids = np.zeros((K, n_features))\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "        cluster_mean = np.mean(X[cluster,:], axis=0) # find new centroid by finding mean of all points assigned to centroid\n",
    "        centroids[cluster_idx] = cluster_mean # collect all centroids\n",
    "    return centroids\n",
    "\n",
    "def is_converged(centroids_old, centroids, K):\n",
    "    \"\"\"Check if centroids have changed since last iteration\"\"\"\n",
    "    distances = [euclidean_distance(centroids_old[i], centroids[i]) for i in range(K)] # check distance between old and new centroids\n",
    "    return sum(distances) == 0 # return Boolean indicating whether centroids are the same as before or not\n",
    "\n",
    "def KMeans_from_scratch(X, K, max_iters):\n",
    "    \"\"\"Choose a random set of centroids then optimise using above functions\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Initialization \n",
    "    random_sample_idx = np.random.choice(n_samples, K, replace=False) # take random sample points to be initial clusters\n",
    "    centroids = [X[idx] for idx in random_sample_idx] # label these points as centroids\n",
    "\n",
    "    iteration_num = 0 # initialize iteration tracker\n",
    "\n",
    "    # Optimization\n",
    "    for iteration in range(max_iters):\n",
    "        \n",
    "        iteration_num += 1 # track iterations required\n",
    "\n",
    "        clusters = create_clusters(K, X, centroids) # assignment to closest centroids (cluster creation)\n",
    "\n",
    "        centroids_old = centroids # archive previous centroids\n",
    "        centroids = update_centroids(X, K, n_features, clusters) # Updating centroids \n",
    "        \n",
    "        # Convergence Confirmation\n",
    "        if is_converged(centroids_old, centroids, K): # check if last iteration's centroids were the same as current iteration\n",
    "            labels = label_cluster(n_samples, clusters)\n",
    "            dist = [euclidean_distance(X[row_num], centroids[int(labels[row_num])]) for row_num in range(X.shape[0])] # get distance from each point to its centroid\n",
    "            total_dist = np.sum(np.square(dist)) # total distance calculated as sum of squares\n",
    "            break # exit loop since there was no change since last iteration\n",
    "\n",
    "    # Classify samples as the index of their clusters\n",
    "    return labels, iteration_num, K, centroids, total_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the implementation by clustering the data created in 2.1 above. We know the data has 4 clusters, so feel free to set $k=4$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Iterations: 4 , No. Centres: 4 , Total Squared Distance 975.9\n",
      "Centroid Coordinates: [[ 5.26709863  3.10485732]\n",
      " [-4.87206772 -2.96119199]\n",
      " [-5.03797103  2.92922372]\n",
      " [ 5.13961914 -2.94559032]]\n",
      "[[-5  3]\n",
      " [-5 -3]\n",
      " [ 5  3]\n",
      " [ 5 -3]]\n",
      "Counter({0.0: 125, 1.0: 125, 2.0: 125, 3.0: 125})\n",
      "Counter({2: 125, 1: 125, 0: 125, 3: 125})\n"
     ]
    }
   ],
   "source": [
    "# Clustering of the artificial data\n",
    "result = KMeans_from_scratch(X, K=4, max_iters=100)\n",
    "#result\n",
    "\n",
    "print(\"No. Iterations:\", result[1], \", No. Centres:\", result[2], \", Total Squared Distance {:.4}\".format(result[4]))\n",
    "\n",
    "print(\"Centroid Coordinates:\", result[3])\n",
    "\n",
    "print(c)\n",
    "\n",
    "from collections import Counter\n",
    "#help(Counter)\n",
    "print(Counter(result[0]))\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Distance function\n",
    "In the lecture, we argued that clustering methods and kMeans are versatile in that the support various distance measures. Let's convince ourself that this is true. Your task is to write a custom function that calculates **cosine similarity**. You can look up the formula of the cosine similarity in the lecture slides of chapter 2, or from the Internet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(x,y):\n",
    "    num = x.dot(y.T)\n",
    "    denom = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "    return num / denom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next thing to do is to change the above from scratch implementation of the kMeans algorithm such that it uses your cosine similarity function for clustering the data. It might be better to copy/past the full kMeans code one more time because this will allow you to have both versions, with Euclidean distance and cosine similarity, in the notebook. This makes it easier to re-run the clustering in case you need or want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kMeans with cosine similarity\n",
    "\n",
    "def label_cluster_cos(n_samples, clusters):\n",
    "    \"\"\"each sample will get the label of the cluster it was assigned to\"\"\"\n",
    "    labels = np.empty(n_samples) # creates empty array as long as samples for future labels\n",
    "\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "        for sample_index in cluster:\n",
    "            labels[sample_index] = cluster_idx # assign labels to each sample\n",
    "    return labels\n",
    "\n",
    "def create_clusters_cos(K, X, centroids):\n",
    "    \"\"\"Assign the samples to the closest centroids to create clusters\"\"\"\n",
    "    clusters = [[] for _ in range(K)] # creates a list of K number of lists\n",
    "    for idx, sample in enumerate(X):\n",
    "        centroid_idx = find_closest_centroid_cos(sample, centroids) # find closest centroid for each sample\n",
    "        clusters[centroid_idx].append(idx) # create index list of closest centroids\n",
    "    return clusters\n",
    "\n",
    "def find_closest_centroid_cos(sample, centroids):\n",
    "    \"\"\"Distance from each sample to every centroid\"\"\"\n",
    "    distances = [cosine_sim(sample, point) for point in centroids] # calculate distance from each sample to each centroid\n",
    "    closest_index = np.argmin(distances) # take closest centroid (one with minimal distance)\n",
    "    return closest_index\n",
    "\n",
    "def update_centroids_cos(X, K, n_features, clusters):\n",
    "    \"\"\"Assign mean value of cluster features to each centroid\"\"\"\n",
    "    centroids = np.zeros((K, n_features))\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "        cluster_mean = np.mean(X[cluster,:], axis=0) # find new centroid by finding mean of all points assigned to centroid\n",
    "        centroids[cluster_idx] = cluster_mean # collect all centroids\n",
    "    return centroids\n",
    "\n",
    "def is_converged_cos(centroids_old, centroids, K):\n",
    "    \"\"\"Check if centroids have changed since last iteration\"\"\"\n",
    "    distances = [cosine_sim(centroids_old[i], centroids[i]) for i in range(K)] # check distance between old and new centroids\n",
    "    return sum(distances) == 0 # return Boolean indicating whether centroids are the same as before or not\n",
    "\n",
    "def KMeans_from_scratch_cos(X, K, max_iters):\n",
    "    \"\"\"Choose a random set of centroids then optimise using above functions\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Initialization \n",
    "    random_sample_idx = np.random.choice(n_samples, K, replace=False) # take random sample points to be initial clusters\n",
    "    centroids = [X[idx] for idx in random_sample_idx] # label these points as centroids\n",
    "\n",
    "    iteration_num = 0 # initialize iteration tracker\n",
    "\n",
    "    # Optimization\n",
    "    for iteration in range(max_iters):\n",
    "        \n",
    "        iteration_num += 1 # track iterations required\n",
    "\n",
    "        clusters = create_clusters_cos(K, X, centroids) # assignment to closest centroids (cluster creation)\n",
    "\n",
    "        centroids_old = centroids # archive previous centroids\n",
    "        centroids = update_centroids_cos(X, K, n_features, clusters) # Updating centroids \n",
    "        \n",
    "        # Convergence Confirmation\n",
    "        if is_converged_cos(centroids_old, centroids, K): # check if last iteration's centroids were the same as current iteration\n",
    "            break # exit loop since there was no change since last iteration\n",
    "    \n",
    "    labels = label_cluster_cos(n_samples, clusters)\n",
    "    dist = [cosine_sim(X[row_num], centroids[int(labels[row_num])]) for row_num in range(X.shape[0])] # get distance from each point to its centroid\n",
    "    total_dist = np.sum(np.square(dist)) # total distance calculated as sum of squares\n",
    "    \n",
    "    # Classify samples as the index of their clusters\n",
    "    return labels, iteration_num, K, centroids, total_dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 New clustering solution\n",
    "The last task on the list is to apply the altered kMeans with cosine similarity to your synthetic data set. Try to come up with a suitable way to compare the results of the two versions of kMeans. It is natural to ask how the cluster solutions differ when using Euclidean distance or cosine similarity. How would you answer that question? Make use of your Python skills to come up with an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 3., 0., 1., 1., 1., 0., 1., 0., 1., 2., 1., 1., 1., 2., 2., 0.,\n",
       "        2., 0., 0., 0., 1., 3., 3., 2., 0., 1., 0., 2., 2., 2., 0., 2., 1.,\n",
       "        1., 2., 1., 0., 0., 3., 2., 1., 0., 3., 1., 0., 0., 1., 3., 1., 3.,\n",
       "        1., 2., 3., 3., 1., 2., 3., 0., 1., 3., 2., 2., 0., 1., 2., 1., 1.,\n",
       "        3., 3., 2., 3., 0., 0., 3., 2., 1., 1., 2., 0., 3., 0., 2., 3., 2.,\n",
       "        2., 3., 3., 0., 2., 0., 2., 0., 0., 3., 3., 3., 2., 3., 2., 1., 2.,\n",
       "        2., 3., 0., 0., 1., 3., 3., 2., 2., 2., 2., 2., 0., 3., 0., 3., 0.,\n",
       "        3., 3., 2., 2., 2., 1., 0., 2., 3., 3., 1., 2., 2., 0., 0., 1., 3.,\n",
       "        2., 2., 3., 3., 1., 2., 2., 2., 2., 0., 3., 3., 2., 1., 0., 3., 0.,\n",
       "        1., 2., 2., 3., 2., 1., 0., 3., 3., 2., 2., 1., 3., 2., 3., 0., 0.,\n",
       "        2., 3., 1., 2., 3., 3., 3., 3., 1., 0., 1., 1., 3., 1., 0., 0., 3.,\n",
       "        0., 3., 3., 1., 3., 0., 3., 2., 1., 2., 1., 3., 1., 3., 3., 0., 0.,\n",
       "        0., 1., 2., 2., 0., 3., 0., 0., 2., 3., 0., 2., 0., 1., 0., 0., 2.,\n",
       "        3., 0., 1., 3., 1., 0., 1., 1., 2., 0., 0., 0., 1., 0., 1., 0., 2.,\n",
       "        3., 0., 3., 2., 0., 2., 0., 1., 1., 3., 2., 2., 3., 2., 2., 2., 1.,\n",
       "        2., 2., 0., 1., 0., 2., 1., 2., 2., 0., 1., 3., 3., 1., 2., 1., 1.,\n",
       "        2., 1., 0., 0., 1., 2., 2., 1., 3., 0., 1., 2., 1., 3., 3., 0., 0.,\n",
       "        3., 0., 2., 3., 0., 2., 0., 0., 3., 1., 3., 2., 3., 2., 2., 0., 1.,\n",
       "        0., 3., 3., 3., 1., 3., 1., 2., 0., 2., 0., 2., 1., 3., 2., 3., 1.,\n",
       "        2., 0., 1., 0., 2., 2., 0., 0., 3., 1., 2., 3., 3., 2., 0., 1., 3.,\n",
       "        0., 0., 0., 3., 2., 3., 1., 3., 0., 3., 0., 2., 2., 0., 1., 2., 0.,\n",
       "        1., 2., 2., 1., 3., 2., 1., 0., 0., 0., 1., 2., 1., 0., 0., 3., 0.,\n",
       "        2., 0., 1., 3., 1., 1., 2., 3., 3., 1., 2., 0., 1., 0., 1., 1., 3.,\n",
       "        0., 3., 1., 3., 0., 2., 1., 3., 1., 3., 3., 3., 0., 0., 1., 3., 1.,\n",
       "        1., 3., 2., 3., 3., 1., 3., 1., 0., 2., 2., 3., 1., 0., 2., 0., 2.,\n",
       "        1., 1., 1., 3., 1., 1., 2., 1., 0., 1., 3., 2., 3., 3., 2., 1., 2.,\n",
       "        0., 0., 1., 0., 1., 1., 1., 2., 0., 1., 1., 0., 0., 3., 3., 1., 1.,\n",
       "        0., 3., 0., 0., 2., 0., 3., 2., 2., 0., 3., 1., 1., 1., 3., 3., 1.,\n",
       "        2., 2., 3., 3., 1., 3., 1., 3., 0., 1., 2., 1., 2., 3., 1., 0., 3.,\n",
       "        1., 3., 1., 0., 2., 2., 0.]),\n",
       " 100,\n",
       " 4,\n",
       " array([[ 5.26709863,  3.10485732],\n",
       "        [-5.03797103,  2.92922372],\n",
       "        [ 5.13961914, -2.94559032],\n",
       "        [-4.87206772, -2.96119199]]),\n",
       " 486.3461552258775)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create cluster solution with the modified kMeans\n",
    "# Clustering of the artificial data\n",
    "result = KMeans_from_scratch_cos(X, K=4, max_iters=100)\n",
    "\n",
    "result\n",
    "\n",
    "#print(\"No. Iterations:\", result[1], \", No. Centres:\", result[2], \", Total Squared Distance {:.4}\".format(result[4]))\n",
    "\n",
    "#print(\"Centroid Coordinates:\", result[3])\n",
    "\n",
    "#print(c)\n",
    "\n",
    "#print(Counter(result[0]))\n",
    "#print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write some code to compare the two cluster solutions from using Euclidean distance and cosine similarity \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Further tasks\n",
    "Still not enough? Ok, that is great! Here are a few ideas for some more tasks associated with kMeans and the scope of this exercise.\n",
    "- Write a custom function calculating the city-block or Manhatten metric\n",
    "- Improve the from scratch implementation of kMeans such that it supports the caller to specify the desired distance function as an argument\n",
    "- The above changes should enable you to flexibly run kMeans with Euclidean, cosine, and city-block distance. Try that out using your synthetic data\n",
    "- Use the `sklearn` function `make_classification()` to generate a more challenging data and apply kMeans to it. You can use your customer implementation of kMeans or the one available in `sklearn`\n",
    "- Run a web-search for the **IRIS data set**. It is a very well known data set. Quickly familiarize yourself with the data. Afterwards, load it using the function `sklearn.datasets.load_iris()`. Check whether kMeans is able to identify the three types of iris flowers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done... puh, that was a lot of work. And you did it! Congratulations!!! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
