{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKxyA3pre2Y_"
   },
   "source": [
    "# Random Forest\n",
    "\n",
    "Even more effective for predictions than decision trees, random forests are useful and powerful ensemble methods for classifying and regressing data. Essentially, a random set of the features are taken to build decision trees. Trees are also built using bagged data which are samples of the data taken with replacement. Many trees are grown (sometimes their maximum depth is also specified) and then all trees vote on the response. Each tree's vote generally has the same weight.\n",
    "\n",
    "Though most of the the time, Sci-Kit Learn can be used to implement this machine learning method simply, it is useful to take a look at the inner workings of these algorithms. This notebook will first introduce a decision tree from scratch. It will then show an example using SK Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYfMGvLWe2ZA"
   },
   "source": [
    "## Random Forest From Scratch Using HMEQ Data\n",
    "\n",
    "Firstly, we will go through a random forest made from scratch. The following code is based on the material originally created by Sebastian Mantey for the Iris Dataset whose GitHub is here: https://github.com/SebastianMantey/Random-Forest-from-Scratch. You can also search his video on YouTube. The code has been adapted to this course's format and fit to HMEQ Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZ7ScTHne2ZA"
   },
   "source": [
    "### Load Relevant Libraries & Data\n",
    "\n",
    "The first decision tree will be coded from scratch using only pandas and NumPy. There are faster ways to do this using Sci-Kit Learn which is a l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9Oof4ROe2ZB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import random #needed for bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWLhAbO-e2ZF"
   },
   "outputs": [],
   "source": [
    "filename = 'https://github.com/Humboldt-WI/bads/blob/master/data/hmeq_modeling.csv?raw=true'\n",
    "df = pd.read_csv(filename, header = 0, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "FyYqXtt3e2ZI",
    "outputId": "aee23c36-30e7-43d9-da5d-dff62d8590cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "      <th>DEROGzero</th>\n",
       "      <th>REASON_HomeImp</th>\n",
       "      <th>REASON_IsMissing</th>\n",
       "      <th>JOB_Office</th>\n",
       "      <th>JOB_Other</th>\n",
       "      <th>JOB_ProfExe</th>\n",
       "      <th>JOB_Sales</th>\n",
       "      <th>JOB_Self</th>\n",
       "      <th>DELINQcat_1</th>\n",
       "      <th>DELINQcat_1+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>-1.832283</td>\n",
       "      <td>-1.295882</td>\n",
       "      <td>-1.335526</td>\n",
       "      <td>0.266788</td>\n",
       "      <td>-1.075278</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-1.297476</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>-1.810666</td>\n",
       "      <td>-0.013474</td>\n",
       "      <td>-0.672699</td>\n",
       "      <td>-0.236615</td>\n",
       "      <td>-0.723092</td>\n",
       "      <td>-0.826792</td>\n",
       "      <td>-0.756608</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>-1.789048</td>\n",
       "      <td>-1.654549</td>\n",
       "      <td>-1.839275</td>\n",
       "      <td>-0.668103</td>\n",
       "      <td>-0.368769</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-1.189302</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>-1.789048</td>\n",
       "      <td>-0.159552</td>\n",
       "      <td>-0.202559</td>\n",
       "      <td>-0.236615</td>\n",
       "      <td>-0.061033</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-0.107566</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>-1.767431</td>\n",
       "      <td>0.791699</td>\n",
       "      <td>0.311107</td>\n",
       "      <td>-0.811933</td>\n",
       "      <td>-1.088528</td>\n",
       "      <td>-0.826792</td>\n",
       "      <td>-0.756608</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BAD      LOAN   MORTDUE  ...  JOB_Self  DELINQcat_1  DELINQcat_1+\n",
       "index                             ...                                     \n",
       "0       True -1.832283 -1.295882  ...         0            0             0\n",
       "1       True -1.810666 -0.013474  ...         0            0             1\n",
       "2       True -1.789048 -1.654549  ...         0            0             0\n",
       "3       True -1.789048 -0.159552  ...         0            0             0\n",
       "4      False -1.767431  0.791699  ...         0            0             0\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "i1Ux0UG9e2ZL",
    "outputId": "1b12dfdf-932c-44b3-b757-62eabe5c39a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "      <th>DEROGzero</th>\n",
       "      <th>REASON_HomeImp</th>\n",
       "      <th>REASON_IsMissing</th>\n",
       "      <th>JOB_Office</th>\n",
       "      <th>JOB_Other</th>\n",
       "      <th>JOB_ProfExe</th>\n",
       "      <th>JOB_Sales</th>\n",
       "      <th>JOB_Self</th>\n",
       "      <th>DELINQcat_1</th>\n",
       "      <th>DELINQcat_1+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.832283</td>\n",
       "      <td>-1.295882</td>\n",
       "      <td>-1.335526</td>\n",
       "      <td>0.266788</td>\n",
       "      <td>-1.075278</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-1.297476</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.810666</td>\n",
       "      <td>-0.013474</td>\n",
       "      <td>-0.672699</td>\n",
       "      <td>-0.236615</td>\n",
       "      <td>-0.723092</td>\n",
       "      <td>-0.826792</td>\n",
       "      <td>-0.756608</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.789048</td>\n",
       "      <td>-1.654549</td>\n",
       "      <td>-1.839275</td>\n",
       "      <td>-0.668103</td>\n",
       "      <td>-0.368769</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-1.189302</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.789048</td>\n",
       "      <td>-0.159552</td>\n",
       "      <td>-0.202559</td>\n",
       "      <td>-0.236615</td>\n",
       "      <td>-0.061033</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-0.107566</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.767431</td>\n",
       "      <td>0.791699</td>\n",
       "      <td>0.311107</td>\n",
       "      <td>-0.811933</td>\n",
       "      <td>-1.088528</td>\n",
       "      <td>-0.826792</td>\n",
       "      <td>-0.756608</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LOAN   MORTDUE     VALUE  ...  JOB_Self  DELINQcat_1  DELINQcat_1+\n",
       "index                                ...                                     \n",
       "0     -1.832283 -1.295882 -1.335526  ...         0            0             0\n",
       "1     -1.810666 -0.013474 -0.672699  ...         0            0             1\n",
       "2     -1.789048 -1.654549 -1.839275  ...         0            0             0\n",
       "3     -1.789048 -0.159552 -0.202559  ...         0            0             0\n",
       "4     -1.767431  0.791699  0.311107  ...         0            0             0\n",
       "\n",
       "[5 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['BAD'], axis=1) #code the variables in the most standard way for your usage\n",
    "y = df[['BAD']]\n",
    "\n",
    "X.head() #inspect that variables were correctly separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "SzCSyD7Ge2ZO",
    "outputId": "acf1dd64-0611-4bc5-fe36-586e63c4618f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BAD\n",
       "index       \n",
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4      False"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "IAGJdNA7e2ZR",
    "outputId": "d543b8f6-ed07-4ced-8405-d056a4169e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> (5960, 18) (5960, 1)\n"
     ]
    }
   ],
   "source": [
    "print(type(X), type(y), X.shape, y.shape) # double check that types and dimensions are correct before proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghRj2IhJe2ZU"
   },
   "source": [
    "### Required Helper Functions for Individual Trees\n",
    "\n",
    "Again, here's how a summary of how individual trees in our forest will work:\n",
    "\n",
    "Many potential ways to split the data are calculated (eg. we are going to go through all unique values of each column and finding the midpoint between sequential values). For each potential split, we evaluate whether the target variable has more homogeneity in each leaf. This is done by calculating 'impurity' of the parent node and comparing it with the sum of the impurity of the child nodes. There are three major impurity functions: entropy, gini and misclassification. We will be using entropy in our example. The split which yields the lowest impurity is chosen and the process is repeated for the new nodes (this is recursion). \n",
    "\n",
    "The method of choosing the split which yields the lowest impurity is called the greedy search method. The following functions will help the decision tree implement greedy search tactics on the data. The algorithm stops either when purity in each node is reached or when it has reached a maximum depth (max amount of recursions we allow) specified in our function.\n",
    "\n",
    "Many functions for the tree are not found in Python packages and it is cleaner to write them out first then put them together in our main algorithm. Each function below does a specific action which will be used in our final tree function at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aD0OZmEe2ZV"
   },
   "outputs": [],
   "source": [
    "def check_purity(y):\n",
    "    \n",
    "    'checks if a leaf node is perfectly pure, in other words, if the leaf node contains only one class'\n",
    "    \n",
    "    unique_classes = np.unique(y) #count number of classes in section of data\n",
    "\n",
    "    if len(unique_classes) == 1: #check if the node is pure\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-Pk6tTTe2ZY"
   },
   "outputs": [],
   "source": [
    "def classify_data(y):\n",
    "    \n",
    "    'classifies data according to the majority class of each leaf'\n",
    "    \n",
    "    unique_classes, counts_unique_classes = np.unique(y, return_counts=True)\n",
    "    #returns classes and no. of obs per class\n",
    "\n",
    "    index = counts_unique_classes.argmax() #index of class with most obs\n",
    "    classification = unique_classes[index] #class chosen for classification which is class with most obs\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pB28rbBoe2Za"
   },
   "outputs": [],
   "source": [
    "def get_potential_splits(X, random_subspace = None):\n",
    "    \n",
    "    'first, takes every unique value of every feature in the feature space, then finds the midpoint between each value'\n",
    "    'modified to add random_subspace for random forest'\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = X.shape #don't need rows, we choose the column to split on\n",
    "    # only need second value of .shape which is columns\n",
    "    column_indices = list(range(n_columns))\n",
    "    \n",
    "    if random_subspace and random_subspace <= len(column_indices): #randomly chosen features\n",
    "        column_indices = random.sample(population=column_indices, k=random_subspace)\n",
    "    \n",
    "    for column_index in column_indices:\n",
    "        potential_splits[column_index] = [] \n",
    "        values = X[:, column_index] \n",
    "        unique_values = np.unique(values) #get all unique values in each column\n",
    "\n",
    "        for index in range(len(unique_values)): #all unique feature values\n",
    "            if index != 0: #skip first value, we need the difference between next values\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index - 1] #find a value and the next smallest value\n",
    "                potential_split = (current_value + previous_value) / 2 #find difference between the two as a potential split\n",
    "                \n",
    "                #consider all values which lie between two values as a potential split\n",
    "                \n",
    "                potential_splits[column_index].append(potential_split)\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6kLufUxe2Zd"
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, split_column, split_value):\n",
    "    \n",
    "    'splits data based on specific value, will yield both a split for the features X and target y'\n",
    "    \n",
    "    split_column_values = X[:, split_column]\n",
    "\n",
    "    X_below = X[split_column_values <= split_value] #partitions data according to split values from previous functions\n",
    "    X_above = X[split_column_values >  split_value]\n",
    "    \n",
    "    y_below = y[split_column_values <= split_value]\n",
    "    y_above = y[split_column_values >  split_value]\n",
    "    \n",
    "    return X_below, X_above, y_below, y_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kc6VPgoZe2Zf"
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(y):\n",
    "    \n",
    "    'calculates entropy for each partition of data'\n",
    "    \n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum() #probability of each class\n",
    "    entropy = sum(probabilities * -np.log2(probabilities)) #could replace with Gini impurity or misclassification\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnRBl4KUe2Zj"
   },
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(y_below, y_above): \n",
    "    \n",
    "    'calculates the total entropy after each split'\n",
    "       \n",
    "    n = len(y_below) + len(y_above)\n",
    "    p_data_below = len(y_below) / n\n",
    "    p_data_above = len(y_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(y_below)\n",
    "                      + p_data_above * calculate_entropy(y_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CE2mvNCDe2Zl"
   },
   "outputs": [],
   "source": [
    "def determine_best_split(X, y, potential_splits):\n",
    "    \n",
    "    'selects which split lowered entropy the most'\n",
    "    \n",
    "    overall_entropy = 9999 #set arbitrarily high, the function will loop over and replace this with lower impurity values\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            X_below, X_above, y_below, y_above = split_data(X, y, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(y_below, y_above)\n",
    "            \n",
    "            #goes through each potential split and only updates if it lowers entropy\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy: \n",
    "                overall_entropy = current_overall_entropy #updates only if lower entropy split found, in the ned this is greedy search\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "            \n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7-hpFq5e2Zn"
   },
   "source": [
    "The tree will now implement the helper functions and display the decision which yielded the best split if printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLJLzoaCe2Zn"
   },
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(X, y, counter=0, min_samples=2, max_depth=5, random_subspace = None): \n",
    "\n",
    "    'same function as in the Decision Tree notebook but now we add random_subspace argument'\n",
    "\n",
    "    # data preparation\n",
    "    if counter == 0: # counter tells us how deep the tree is, this is before the tree is initiated\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = X.columns\n",
    "        X = X.values #change all to NumPy array for faster calculations\n",
    "        y = y.values\n",
    "    else:\n",
    "        data = X #if we have started the tree, X should already be a NumPy array from the code above \n",
    "    \n",
    "    # base cases\n",
    "    if (check_purity(y)) or (len(X) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(y)\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1 #tells us how deep the tree is\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(X, random_subspace) #check for all possible splits ONLY using the random subspace and not all features!\n",
    "        best_split_column, best_split_value = determine_best_split(X, y, potential_splits) #select best split based on entropy\n",
    "        X_below, X_above, y_below, y_above = split_data(X, y, best_split_column, best_split_value) #execute best split\n",
    "        \n",
    "        # code to explain decisions made by tree to users\n",
    "        feature_name = COLUMN_HEADERS[best_split_column]\n",
    "        question = \"{} <= {}\".format(feature_name, best_split_value) #initiate explanation of split\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # pull answers from tree\n",
    "        yes_answer = decision_tree_algorithm(X_below, y_below, counter, min_samples, max_depth, random_subspace)\n",
    "        no_answer = decision_tree_algorithm(X_above, y_above, counter, min_samples, max_depth, random_subspace)\n",
    "        \n",
    "        # ensure explanation actually shows useful information\n",
    "        if yes_answer == no_answer: #if decisions are the same, only display one\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yZntzgne2Zq"
   },
   "source": [
    "### Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9TppSOUVe2Zq"
   },
   "outputs": [],
   "source": [
    "def bootstrapping(X, y, n_bootstrap):\n",
    "\n",
    "  'takes a random set of observations of the size n_bootstrap'\n",
    "\n",
    "    bootstrap_indices = np.random.randint(low=0, high=len(X), size=n_bootstrap) #chooses random indices for the sample\n",
    "    X_bootstrapped = X.iloc[bootstrap_indices]\n",
    "    y_bootstrapped = y.iloc[bootstrap_indices]\n",
    "    \n",
    "    return X_bootstrapped, y_bootstrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJp8a_tpe2Zu"
   },
   "outputs": [],
   "source": [
    "def random_forest_algorithm(X, y, n_trees, n_bootstrap, n_features, dt_max_depth):\n",
    "  'puts the bootstrap sample in the decision tree algorithm with max depth and the random subset of features set, in otherwords, builds the forest tree by tree'\n",
    "\n",
    "    forest = []\n",
    "    for i in range(n_trees): #loops for the amount of trees set to be in the forest\n",
    "        X_bootstrapped, y_bootstrapped = bootstrapping(X, y, n_bootstrap)\n",
    "        tree = decision_tree_algorithm(X_bootstrapped, y_bootstrapped, max_depth=dt_max_depth, random_subspace=n_features) #creates individual trees\n",
    "        forest.append(tree)\n",
    "    \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NCdqwHoe2Zw"
   },
   "outputs": [],
   "source": [
    "def predict_example(example, tree, counter=0):\n",
    "\n",
    "  'takes one observation and predicts its class'\n",
    "    \n",
    "    if counter == 0 and isinstance(tree, dict) == False: # very shallow tree settings may only vote one way, this first if-statement takes its vote into account\n",
    "        return tree\n",
    "    \n",
    "    else:\n",
    "        counter += 1\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    \n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return predict_example(example, residual_tree)\n",
    "\n",
    "    \n",
    "# Gathers all test data\n",
    "def decision_tree_predictions(test_df, tree):\n",
    "  \n",
    "  'applies predict_example to all of the test set'\n",
    "\n",
    "    predictions = test_df.apply(predict_example, args=(tree,), axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3yXFPG8e2Zz"
   },
   "outputs": [],
   "source": [
    "def random_forest_predictions(test_df, forest):\n",
    "    df_predictions = {}\n",
    "    for i in range(len(forest)):\n",
    "        column_name = \"tree_{}\".format(i) #key for dictionary\n",
    "        predictions = decision_tree_predictions(test_df, tree=forest[i]) #predictions from trees\n",
    "        df_predictions[column_name] = predictions #insert predictions into dictionary\n",
    "\n",
    "    df_predictions = pd.DataFrame(df_predictions) #change dictionary to pandas DF\n",
    "    random_forest_predictions = df_predictions.mode(axis=1)[0] #take mode of predictions over trees for final prediction\n",
    "    #if there is an even number of predictions, just default to the first value (very unlikely with many trees)\n",
    "    \n",
    "    return random_forest_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mot6Okr5e2Z1"
   },
   "source": [
    "### Grow Forest\n",
    "\n",
    "Test the forest and display the decisions with a shallow depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rw92_Ssqe2Z2"
   },
   "outputs": [],
   "source": [
    "forest = random_forest_algorithm(X, y, n_trees=50, n_bootstrap=800, n_features=8, dt_max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "LmEZQNMse2Z6",
    "outputId": "971d0fde-f498-414f-c840-e15037426d8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOAN <= -1.081076960402989': [{'MORTDUE <= -0.9988023477260403': [{'JOB_Self <= 0.5': [True,\n",
       "      {'CLAGE <= 1.319329723705905': [False, True]}]},\n",
       "    {'DEBTINC <= -0.36610310502357446': [{'JOB_Sales <= 0.5': [False, True]},\n",
       "      {'YOJ <= -0.5961885016974147': [{'VALUE <= -1.2866632148005883': [True,\n",
       "          False]},\n",
       "        {'CLNO <= -0.43208664907294947': [True, False]}]}]}]},\n",
       "  {'NINQ <= 0.3158144850582817': [{'DEBTINC <= 1.9169228230498017': [False,\n",
       "      True]},\n",
       "    {'DELINQcat_1+ <= 0.5': [{'CLAGE <= 0.0485464889016222': [{'CLAGE <= -1.4443818774196413': [True,\n",
       "          False]},\n",
       "        False]},\n",
       "      {'CLNO <= 0.5955631974189916': [{'CLNO <= -0.05347881089170803': [True,\n",
       "          False]},\n",
       "        True]}]}]}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRV04WBke2Z9"
   },
   "outputs": [],
   "source": [
    "predictions = random_forest_predictions(X, forest) #get predictions from forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "upoB6SxNe2Z_",
    "outputId": "a8d8be81-1429-43cf-d3ff-dd6264181ce1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701342281879194"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = np.mean(np.vstack(predictions) == np.array(y)) #check error rate\n",
    "\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfeanJuve2aB"
   },
   "source": [
    "The tree is able to classify a good proportion of the test set well even with only a depth of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu-jGsNQe2aB"
   },
   "source": [
    "## Random Forest with Sci-Kit Learn\n",
    "\n",
    "As mentioned, the package Ski-Kit Learn has prebuilt functions which avoid coding most algorithms by scratch. Now armed with the knowledge of the inner workings of the decision tree, it should be easier to understand what this algorithm is trying to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "8BTpKLuse2aC",
    "outputId": "4883b1fb-f2b4-4ee4-ad95-9088fe455d28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=800, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwfMH07Ze2aE"
   },
   "outputs": [],
   "source": [
    "pred_sklearn = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "OUsWIk_Je2aI",
    "outputId": "4db55048-ba76-4768-9bd1-4e98e6790bcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sklearn[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "msJPTlbqe2aK",
    "outputId": "601658d9-72f1-4055-cb2f-d276fe52b4ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9125"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_sklearn = (pred_sklearn == y).mean()\n",
    "\n",
    "\n",
    "error_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7BIquL3e2aN"
   },
   "source": [
    "### SK Random Forest with Different Feature Space\n",
    "\n",
    "If we allow for more features to be used, we may get better results but with all features. However, using too many features is essentially creating very similar trees which decreases the effectiveness of this ensemble method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "jZprVvrNe2aN",
    "outputId": "1a7f8d76-49c6-4e6a-b455-1a2adbc2e0e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=5, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=800, n_features=7,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "\n",
    "clf2 = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rt4aRyF2e2aP"
   },
   "outputs": [],
   "source": [
    "pred_sklearn2 = clf2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "uGqC2-T0e2aR",
    "outputId": "f5635556-ec6a-4147-fb0d-89b05ac5883e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92625"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_sklearn2 = (pred_sklearn2 == y).mean()\n",
    "\n",
    "error_sklearn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifrl_dn7e2aV"
   },
   "source": [
    "Questions to think about: if we are using bagging and random feature spaces correctly, how are we avoiding the common machine learning problem of overfitting?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Random Forest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
